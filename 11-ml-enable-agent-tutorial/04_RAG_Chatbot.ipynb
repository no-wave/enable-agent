{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Agent Tutorial Part 4: RAG 챗봇 및 보고서 생성\n",
    "\n",
    "## 개요\n",
    "\n",
    "Part 3에서 구축한 지식 베이스를 활용하여 대화형 RAG 챗봇을 구현한다.\n",
    "\n",
    "## RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "```\n",
    "+------------------+\n",
    "|  사용자 질문     |\n",
    "+--------+---------+\n",
    "         v\n",
    "+-----------------------------+\n",
    "|  IrisRAGChatbot             |\n",
    "+-----------------------------+\n",
    "| 1. 지식 베이스 검색         | <- knowledge_base.txt\n",
    "| 2. 필요시 Agent 호출        | <- IrisEnableAgent\n",
    "| 3. LLM으로 응답 생성        | <- OpenAI GPT-4\n",
    "| 4. 컨텍스트 자동 업데이트   | -> context_store/\n",
    "+-----------------------------+\n",
    "         v\n",
    "+------------------+\n",
    "|  자연어 응답     |\n",
    "+------------------+\n",
    "```\n",
    "\n",
    "## 학습 내용\n",
    "\n",
    "- RAG 챗봇 구현\n",
    "- 대화형 예측 인터페이스\n",
    "- 자동 분석 보고서 생성\n",
    "- 통합 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "print(\"라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. IrisEnableAgent 클래스 (Part 2에서 재사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisEnableAgent 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class IrisEnableAgent:\n",
    "    \"\"\"Iris 분류 모델을 Enable Agent로 래핑한 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, skill_path: str):\n",
    "        with open(skill_path, 'r', encoding='utf-8') as f:\n",
    "            self.skill = yaml.safe_load(f)\n",
    "        \n",
    "        model_path = self.skill['model_info']['model_path']\n",
    "        self.model = joblib.load(model_path)\n",
    "        \n",
    "        metadata_path = self.skill['model_info']['metadata_path']\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        self.client = OpenAI()\n",
    "        \n",
    "        print(f\"Enable Agent 초기화 완료: {self.skill['agent_name']}\")\n",
    "        print(f\"모델 정확도: {self.metadata['accuracy']:.4f}\")\n",
    "    \n",
    "    def get_capability_description(self) -> str:\n",
    "        return f\"\"\"\n",
    "Agent 이름: {self.skill['agent_name']}\n",
    "버전: {self.skill['version']}\n",
    "설명: {self.skill['description']}\n",
    "\n",
    "주요 기능: {self.skill['capabilities']['primary']}\n",
    "부가 기능: {', '.join(self.skill['capabilities']['secondary'])}\n",
    "\n",
    "입력 파라미터:\n",
    "- sepal_length: 꽃받침 길이 (cm, 4.0-8.0)\n",
    "- sepal_width: 꽃받침 너비 (cm, 2.0-5.0)\n",
    "- petal_length: 꽃잎 길이 (cm, 1.0-7.0)\n",
    "- petal_width: 꽃잎 너비 (cm, 0.1-3.0)\n",
    "\n",
    "출력:\n",
    "- predicted_class: 예측된 붓꽃 품종 (setosa, versicolor, virginica)\n",
    "- confidence: 예측 신뢰도 (0-1)\n",
    "- probabilities: 각 클래스별 확률\n",
    "- feature_importance: 특성별 중요도\n",
    "\n",
    "모델 정보:\n",
    "- 타입: {self.metadata['model_type']}\n",
    "- 정확도: {self.metadata['accuracy']:.4f}\n",
    "- 학습 샘플: {self.metadata['training_samples']}개\n",
    "\"\"\".strip()\n",
    "    \n",
    "    def validate_input(self, input_data: Dict[str, float]) -> Tuple[bool, str]:\n",
    "        required_fields = self.skill['input_schema']['required']\n",
    "        properties = self.skill['input_schema']['properties']\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field not in input_data:\n",
    "                return False, f\"필수 필드 누락: {field}\"\n",
    "        \n",
    "        for field, value in input_data.items():\n",
    "            if field in properties:\n",
    "                prop = properties[field]\n",
    "                if 'minimum' in prop and value < prop['minimum']:\n",
    "                    return False, f\"{field}가 최소값({prop['minimum']})보다 작다: {value}\"\n",
    "                if 'maximum' in prop and value > prop['maximum']:\n",
    "                    return False, f\"{field}가 최대값({prop['maximum']})보다 크다: {value}\"\n",
    "        \n",
    "        return True, \"유효한 입력\"\n",
    "    \n",
    "    def predict(self, input_data: Dict[str, float]) -> Dict[str, Any]:\n",
    "        is_valid, message = self.validate_input(input_data)\n",
    "        if not is_valid:\n",
    "            raise ValueError(message)\n",
    "        \n",
    "        feature_names = self.metadata['feature_names']\n",
    "        X = np.array([[\n",
    "            input_data['sepal_length'],\n",
    "            input_data['sepal_width'],\n",
    "            input_data['petal_length'],\n",
    "            input_data['petal_width']\n",
    "        ]])\n",
    "        \n",
    "        prediction = self.model.predict(X)[0]\n",
    "        probabilities = self.model.predict_proba(X)[0]\n",
    "        \n",
    "        target_names = self.metadata['target_names']\n",
    "        predicted_class = target_names[prediction]\n",
    "        confidence = float(probabilities[prediction])\n",
    "        \n",
    "        feature_importance = dict(zip(\n",
    "            feature_names,\n",
    "            self.model.feature_importances_.tolist()\n",
    "        ))\n",
    "        \n",
    "        return {\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"confidence\": confidence,\n",
    "            \"probabilities\": dict(zip(target_names, probabilities.tolist())),\n",
    "            \"feature_importance\": feature_importance,\n",
    "            \"input_features\": input_data,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def generate_tool_definition(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"predict_iris_species\",\n",
    "                \"description\": self.skill['description'],\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"sepal_length\": {\"type\": \"number\", \"description\": \"꽃받침 길이 (cm)\"},\n",
    "                        \"sepal_width\": {\"type\": \"number\", \"description\": \"꽃받침 너비 (cm)\"},\n",
    "                        \"petal_length\": {\"type\": \"number\", \"description\": \"꽃잎 길이 (cm)\"},\n",
    "                        \"petal_width\": {\"type\": \"number\", \"description\": \"꽃잎 너비 (cm)\"}\n",
    "                    },\n",
    "                    \"required\": [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"IrisEnableAgent 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. PredictionContextBuilder 클래스 (Part 3에서 재사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionContextBuilder 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class PredictionContextBuilder:\n",
    "    \"\"\"예측 결과를 컨텍스트로 저장하고 관리하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, context_dir: str = 'context_store'):\n",
    "        self.context_dir = Path(context_dir)\n",
    "        self.context_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.log_file = self.context_dir / 'prediction_logs.json'\n",
    "        self.summary_file = self.context_dir / 'prediction_summary.json'\n",
    "        self.knowledge_base_file = self.context_dir / 'knowledge_base.txt'\n",
    "        \n",
    "        self.logs = self._load_logs()\n",
    "        \n",
    "        print(f\"Context Builder 초기화 완료\")\n",
    "        print(f\"저장된 예측 로그: {len(self.logs)}개\")\n",
    "    \n",
    "    def _load_logs(self) -> List[Dict[str, Any]]:\n",
    "        if self.log_file.exists():\n",
    "            with open(self.log_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return []\n",
    "    \n",
    "    def add_prediction(self, prediction_result: Dict[str, Any]):\n",
    "        self.logs.append(prediction_result)\n",
    "        \n",
    "        with open(self.log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.logs, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"예측 결과 저장 완료 (총 {len(self.logs)}개)\")\n",
    "        \n",
    "        self._update_summary()\n",
    "        self._update_knowledge_base()\n",
    "    \n",
    "    def _update_summary(self):\n",
    "        if not self.logs:\n",
    "            return\n",
    "        \n",
    "        total_predictions = len(self.logs)\n",
    "        class_counts = {}\n",
    "        confidence_sum = 0\n",
    "        \n",
    "        for log in self.logs:\n",
    "            predicted_class = log['predicted_class']\n",
    "            class_counts[predicted_class] = class_counts.get(predicted_class, 0) + 1\n",
    "            confidence_sum += log['confidence']\n",
    "        \n",
    "        avg_confidence = confidence_sum / total_predictions\n",
    "        \n",
    "        feature_stats = {'sepal_length': [], 'sepal_width': [], 'petal_length': [], 'petal_width': []}\n",
    "        for log in self.logs:\n",
    "            for feature, value in log['input_features'].items():\n",
    "                feature_stats[feature].append(value)\n",
    "        \n",
    "        feature_averages = {feature: sum(values) / len(values) for feature, values in feature_stats.items()}\n",
    "        \n",
    "        summary = {\n",
    "            \"total_predictions\": total_predictions,\n",
    "            \"class_distribution\": class_counts,\n",
    "            \"average_confidence\": avg_confidence,\n",
    "            \"feature_averages\": feature_averages,\n",
    "            \"last_updated\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(self.summary_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    def _update_knowledge_base(self):\n",
    "        if not self.logs:\n",
    "            return\n",
    "        \n",
    "        with open(self.summary_file, 'r', encoding='utf-8') as f:\n",
    "            summary = json.load(f)\n",
    "        \n",
    "        knowledge_text = f\"\"\"# Iris 분류 모델 예측 지식 베이스\n",
    "\n",
    "## 전체 통계 (마지막 업데이트: {summary['last_updated']})\n",
    "\n",
    "총 예측 수행 횟수: {summary['total_predictions']}회\n",
    "평균 예측 신뢰도: {summary['average_confidence']:.2%}\n",
    "\n",
    "## 품종별 예측 분포\\n\\n\"\"\"\n",
    "        \n",
    "        for species, count in summary['class_distribution'].items():\n",
    "            percentage = (count / summary['total_predictions']) * 100\n",
    "            knowledge_text += f\"- {species}: {count}회 ({percentage:.1f}%)\\n\"\n",
    "        \n",
    "        knowledge_text += \"\\n## 평균 특성 값\\n\\n\"\n",
    "        for feature, avg_value in summary['feature_averages'].items():\n",
    "            knowledge_text += f\"- {feature}: {avg_value:.2f} cm\\n\"\n",
    "        \n",
    "        knowledge_text += \"\\n## 최근 예측 기록 (최근 5개)\\n\\n\"\n",
    "        recent_logs = self.logs[-5:]\n",
    "        for i, log in enumerate(reversed(recent_logs), 1):\n",
    "            knowledge_text += f\"### 예측 #{len(self.logs) - i + 1}\\n\"\n",
    "            knowledge_text += f\"- 예측 품종: {log['predicted_class']}\\n\"\n",
    "            knowledge_text += f\"- 신뢰도: {log['confidence']:.2%}\\n\\n\"\n",
    "        \n",
    "        with open(self.knowledge_base_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(knowledge_text.strip())\n",
    "    \n",
    "    def get_knowledge_base_content(self) -> str:\n",
    "        if self.knowledge_base_file.exists():\n",
    "            with open(self.knowledge_base_file, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        return \"\"\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        if self.summary_file.exists():\n",
    "            with open(self.summary_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "\n",
    "print(\"PredictionContextBuilder 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. IrisRAGChatbot 클래스 구현\n",
    "\n",
    "### 핵심 기능\n",
    "\n",
    "- **지식 베이스 통합**: 과거 예측 결과를 컨텍스트로 활용\n",
    "- **Function Calling**: 실시간 예측 수행\n",
    "- **자동 컨텍스트 업데이트**: 새로운 예측을 지식 베이스에 추가\n",
    "- **보고서 생성**: 전체 예측 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisRAGChatbot 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class IrisRAGChatbot:\n",
    "    \"\"\"Iris 예측 지식을 활용하는 RAG 챗봇\"\"\"\n",
    "    \n",
    "    def __init__(self, agent, context_builder):\n",
    "        self.agent = agent\n",
    "        self.context_builder = context_builder\n",
    "        self.client = OpenAI()\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        print(\"RAG 챗봇 초기화 완료\")\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        knowledge_base = self.context_builder.get_knowledge_base_content()\n",
    "        agent_capability = self.agent.get_capability_description()\n",
    "        \n",
    "        return f\"\"\"\n",
    "당신은 Iris(붓꽃) 품종 분류 전문가 AI 어시스턴트다.\n",
    "다음과 같은 역할을 수행한다:\n",
    "\n",
    "1. 사용자의 붓꽃 측정 데이터를 받아 품종을 예측한다\n",
    "2. 과거 예측 기록을 바탕으로 통계와 인사이트를 제공한다\n",
    "3. 붓꽃 품종의 특징과 구별 방법을 설명한다\n",
    "4. 예측 결과에 대한 상세한 분석과 해석을 제공한다\n",
    "\n",
    "## 사용 가능한 도구\n",
    "\n",
    "{agent_capability}\n",
    "\n",
    "## 과거 예측 지식 베이스\n",
    "\n",
    "{knowledge_base}\n",
    "\n",
    "## 응답 가이드라인\n",
    "\n",
    "- 친절하고 전문적인 톤을 유지한다\n",
    "- 기술 용어를 사용할 때는 쉬운 설명을 덧붙인다\n",
    "- 과거 예측 데이터를 활용하여 맥락있는 답변을 제공한다\n",
    "- 예측 요청 시 predict_iris_species 함수를 호출한다\n",
    "- 문장의 끝은 ~다로 끝낸다\n",
    "\"\"\".strip()\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": self._get_system_prompt()}] + self.conversation_history\n",
    "        tools = [self.agent.generate_tool_definition()]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        response_message = response.choices[0].message\n",
    "        \n",
    "        if response_message.tool_calls:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if function_name == \"predict_iris_species\":\n",
    "                    prediction_result = self.agent.predict(function_args)\n",
    "                    self.context_builder.add_prediction(prediction_result)\n",
    "                    \n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": None,\n",
    "                        \"tool_calls\": [tool_call]\n",
    "                    })\n",
    "                    \n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(prediction_result, ensure_ascii=False)\n",
    "                    })\n",
    "            \n",
    "            messages = [{\"role\": \"system\", \"content\": self._get_system_prompt()}] + self.conversation_history\n",
    "            \n",
    "            final_response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            assistant_message = final_response.choices[0].message.content\n",
    "        else:\n",
    "            assistant_message = response_message.content\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        summary = self.context_builder.get_summary()\n",
    "        knowledge_base = self.context_builder.get_knowledge_base_content()\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"당신은 데이터 분석 보고서를 작성하는 전문가다. 주어진 예측 데이터를 분석하여 경영진이 이해하기 쉬운 보고서를 작성한다. 문장의 끝은 ~다로 끝낸다.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "다음 Iris 품종 분류 예측 데이터를 바탕으로 상세한 분석 보고서를 작성해달라:\n",
    "\n",
    "## 요약 통계\n",
    "{json.dumps(summary, indent=2, ensure_ascii=False)}\n",
    "\n",
    "## 상세 예측 기록\n",
    "{knowledge_base}\n",
    "\n",
    "보고서에 다음 내용을 포함해달라:\n",
    "1. 전체 예측 성능 요약\n",
    "2. 품종별 예측 패턴 분석\n",
    "3. 주요 특성별 경향성\n",
    "4. 인사이트 및 권장사항\n",
    "5. 향후 개선 방향\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        self.conversation_history = []\n",
    "        print(\"대화 히스토리 초기화 완료\")\n",
    "\n",
    "print(\"IrisRAGChatbot 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. RAG 챗봇 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable Agent 초기화 완료: Iris Classification Agent\n",
      "모델 정확도: 0.9333\n",
      "Context Builder 초기화 완료\n",
      "저장된 예측 로그: 10개\n",
      "RAG 챗봇 초기화 완료\n",
      "\n",
      "모든 컴포넌트 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "agent = IrisEnableAgent('skills/iris_agent_skill.yaml')\n",
    "context_builder = PredictionContextBuilder()\n",
    "chatbot = IrisRAGChatbot(agent, context_builder)\n",
    "\n",
    "print(\"\\n모든 컴포넌트 초기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 대화형 데모\n",
    "\n",
    "RAG 챗봇과 대화하며 붓꽃 품종을 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_demo(user_input: str) -> str:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"사용자: {user_input}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    response = chatbot.chat(user_input)\n",
    "    \n",
    "    print(f\"챗봇: {response}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: 안녕하세요! 붓꽃 품종 분류에 대해 알려주세요.\n",
      "----------------------------------------------------------------------\n",
      "챗봇: 안녕하세요! 붓꽃 품종 분류에 대해 알려드리겠습니다. 붓꽃(Iris) 분류는 주로 세 가지 품종으로 나뉩니다: Setosa, Versicolor, Virginica입니다. 이들은 꽃받침 길이와 너비(sepal length and width), 꽃잎 길이와 너비(petal length and width)라는 네 가지 주요 특성에 기반하여 구분됩니다.\n",
      "\n",
      "1. **Setosa**: 일반적으로 꽃잎이 짧고 넓으며, 꽃받침도 다른 두 품종에 비해 상대적으로 넓습니다. 주로 꽃잎 길이가 1.0-1.9 cm 정도로 매우 짧습니다.\n",
      "\n",
      "2. **Versicolor**: Setosa보다는 꽃잎이 길고, Virginica보다는 짧습니다. 꽃잎 길이는 3.0-5.0 cm 정도이며, 다양한 색상을 가진 꽃잎을 가지고 있습니다.\n",
      "\n",
      "3. **Virginica**: 가장 크고 긴 꽃잎을 가진 품종입니다. 꽃잎 길이는 보통 4.5-6.9 cm 정도로 아주 길며, 꽃받침도 다른 두 품종에 비해 더 깁니다.\n",
      "\n",
      "붓꽃 분류는 주로 머신러닝 모델을 사용하여 자동으로 이루어지며, 각 특성의 측정 값을 입력으로 받아 품종을 예측합니다. 이 과정에서 주로 사용되는 모델은 RandomForestClassifier 같은 분류 알고리즘입니다. 이 모델은 각 특성의 중요도를 평가하여 품종을 예측하는 데 사용됩니다.\n",
      "\n",
      "추가 질문이 있거나 붓꽃 측정 데이터를 제공해주시면, 예측을 도와드리겠습니다!\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 붓꽃 품종 분류에 대해 알려드리겠습니다. 붓꽃(Iris) 분류는 주로 세 가지 품종으로 나뉩니다: Setosa, Versicolor, Virginica입니다. 이들은 꽃받침 길이와 너비(sepal length and width), 꽃잎 길이와 너비(petal length and width)라는 네 가지 주요 특성에 기반하여 구분됩니다.\\n\\n1. **Setosa**: 일반적으로 꽃잎이 짧고 넓으며, 꽃받침도 다른 두 품종에 비해 상대적으로 넓습니다. 주로 꽃잎 길이가 1.0-1.9 cm 정도로 매우 짧습니다.\\n\\n2. **Versicolor**: Setosa보다는 꽃잎이 길고, Virginica보다는 짧습니다. 꽃잎 길이는 3.0-5.0 cm 정도이며, 다양한 색상을 가진 꽃잎을 가지고 있습니다.\\n\\n3. **Virginica**: 가장 크고 긴 꽃잎을 가진 품종입니다. 꽃잎 길이는 보통 4.5-6.9 cm 정도로 아주 길며, 꽃받침도 다른 두 품종에 비해 더 깁니다.\\n\\n붓꽃 분류는 주로 머신러닝 모델을 사용하여 자동으로 이루어지며, 각 특성의 측정 값을 입력으로 받아 품종을 예측합니다. 이 과정에서 주로 사용되는 모델은 RandomForestClassifier 같은 분류 알고리즘입니다. 이 모델은 각 특성의 중요도를 평가하여 품종을 예측하는 데 사용됩니다.\\n\\n추가 질문이 있거나 붓꽃 측정 데이터를 제공해주시면, 예측을 도와드리겠습니다!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"안녕하세요! 붓꽃 품종 분류에 대해 알려주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: 꽃받침 길이 5.1cm, 꽃받침 너비 3.5cm, 꽃잎 길이 1.4cm, 꽃잎 너비 0.2cm인 붓꽃은 어떤 품종일까요?\n",
      "----------------------------------------------------------------------\n",
      "예측 결과 저장 완료 (총 11개)\n",
      "챗봇: 입력하신 꽃받침 길이 5.1cm, 꽃받침 너비 3.5cm, 꽃잎 길이 1.4cm, 꽃잎 너비 0.2cm인 붓꽃은 **Setosa** 품종으로 예측되었습니다. 예측 신뢰도는 100%입니다, 즉 매우 높은 확신을 가지고 있습니다.\n",
      "\n",
      "특성의 중요도를 보면, 꽃잎 길이와 꽃잎 너비가 가장 큰 영향을 미쳤습니다. 이는 Setosa 품종이 일반적으로 짧고 넓은 꽃잎을 가진다는 특징과 일치합니다.\n",
      "\n",
      "추가 질문이 있거나 또 다른 예측을 원하시면 언제든지 말씀해 주세요!\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'입력하신 꽃받침 길이 5.1cm, 꽃받침 너비 3.5cm, 꽃잎 길이 1.4cm, 꽃잎 너비 0.2cm인 붓꽃은 **Setosa** 품종으로 예측되었습니다. 예측 신뢰도는 100%입니다, 즉 매우 높은 확신을 가지고 있습니다.\\n\\n특성의 중요도를 보면, 꽃잎 길이와 꽃잎 너비가 가장 큰 영향을 미쳤습니다. 이는 Setosa 품종이 일반적으로 짧고 넓은 꽃잎을 가진다는 특징과 일치합니다.\\n\\n추가 질문이 있거나 또 다른 예측을 원하시면 언제든지 말씀해 주세요!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"꽃받침 길이 5.1cm, 꽃받침 너비 3.5cm, 꽃잎 길이 1.4cm, 꽃잎 너비 0.2cm인 붓꽃은 어떤 품종일까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: 이번에는 꽃받침 길이 6.3cm, 꽃받침 너비 3.3cm, 꽃잎 길이 6.0cm, 꽃잎 너비 2.5cm인 붓꽃을 예측해주세요.\n",
      "----------------------------------------------------------------------\n",
      "예측 결과 저장 완료 (총 12개)\n",
      "챗봇: 입력하신 꽃받침 길이 6.3cm, 꽃받침 너비 3.3cm, 꽃잎 길이 6.0cm, 꽃잎 너비 2.5cm인 붓꽃은 **Virginica** 품종으로 예측되었습니다. 예측 신뢰도는 100%입니다, 즉 매우 높은 확신을 가지고 있습니다.\n",
      "\n",
      "Virginica 품종은 일반적으로 가장 긴 꽃잎과 넓은 꽃잎을 갖고 있으며, 제공된 특성 값은 이 품종의 전형적인 특징과 잘 맞아떨어집니다. 이 예측에서도 꽃잎 길이와 너비가 가장 중요하게 작용했습니다.\n",
      "\n",
      "추가 질문이나 다른 예측을 원하시면 언제든지 말씀해 주세요!\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'입력하신 꽃받침 길이 6.3cm, 꽃받침 너비 3.3cm, 꽃잎 길이 6.0cm, 꽃잎 너비 2.5cm인 붓꽃은 **Virginica** 품종으로 예측되었습니다. 예측 신뢰도는 100%입니다, 즉 매우 높은 확신을 가지고 있습니다.\\n\\nVirginica 품종은 일반적으로 가장 긴 꽃잎과 넓은 꽃잎을 갖고 있으며, 제공된 특성 값은 이 품종의 전형적인 특징과 잘 맞아떨어집니다. 이 예측에서도 꽃잎 길이와 너비가 가장 중요하게 작용했습니다.\\n\\n추가 질문이나 다른 예측을 원하시면 언제든지 말씀해 주세요!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"이번에는 꽃받침 길이 6.3cm, 꽃받침 너비 3.3cm, 꽃잎 길이 6.0cm, 꽃잎 너비 2.5cm인 붓꽃을 예측해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: 지금까지의 예측 통계를 알려주세요.\n",
      "----------------------------------------------------------------------\n",
      "챗봇: 현재까지의 예측 통계는 다음과 같습니다:\n",
      "\n",
      "### 전체 통계\n",
      "- 총 예측 수행 횟수: 14회\n",
      "- 평균 예측 신뢰도: 96.49%\n",
      "\n",
      "### 품종별 예측 분포\n",
      "- Setosa: 5회 (35.7%)\n",
      "- Versicolor: 3회 (21.4%)\n",
      "- Virginica: 6회 (42.9%)\n",
      "\n",
      "### 평균 특성 값\n",
      "- 꽃받침 길이: 5.89 cm\n",
      "- 꽃받침 너비: 3.15 cm\n",
      "- 꽃잎 길이: 4.43 cm\n",
      "- 꽃잎 너비: 1.56 cm\n",
      "\n",
      "### 최근 예측 기록 (최근 5개)\n",
      "1. 예측 품종: Virginica\n",
      "   - 신뢰도: 100.00%\n",
      "2. 예측 품종: Setosa\n",
      "   - 신뢰도: 100.00%\n",
      "3. 예측 품종: Virginica\n",
      "   - 신뢰도: 100.00%\n",
      "4. 예측 품종: Virginica\n",
      "   - 신뢰도: 100.00%\n",
      "5. 예측 품종: Virginica\n",
      "   - 신뢰도: 100.00%\n",
      "\n",
      "이 통계는 최근 예측 기록과 각 품종별 예측 분포를 포함하고 있습니다. 추가적인 분석이나 다른 질문이 있으시면 언제든지 말씀해 주세요!\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'현재까지의 예측 통계는 다음과 같습니다:\\n\\n### 전체 통계\\n- 총 예측 수행 횟수: 14회\\n- 평균 예측 신뢰도: 96.49%\\n\\n### 품종별 예측 분포\\n- Setosa: 5회 (35.7%)\\n- Versicolor: 3회 (21.4%)\\n- Virginica: 6회 (42.9%)\\n\\n### 평균 특성 값\\n- 꽃받침 길이: 5.89 cm\\n- 꽃받침 너비: 3.15 cm\\n- 꽃잎 길이: 4.43 cm\\n- 꽃잎 너비: 1.56 cm\\n\\n### 최근 예측 기록 (최근 5개)\\n1. 예측 품종: Virginica\\n   - 신뢰도: 100.00%\\n2. 예측 품종: Setosa\\n   - 신뢰도: 100.00%\\n3. 예측 품종: Virginica\\n   - 신뢰도: 100.00%\\n4. 예측 품종: Virginica\\n   - 신뢰도: 100.00%\\n5. 예측 품종: Virginica\\n   - 신뢰도: 100.00%\\n\\n이 통계는 최근 예측 기록과 각 품종별 예측 분포를 포함하고 있습니다. 추가적인 분석이나 다른 질문이 있으시면 언제든지 말씀해 주세요!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"지금까지의 예측 통계를 알려주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 분석 보고서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 보고서 생성 중...\n",
      "\n",
      "======================================================================\n",
      "Iris 품종 분류 분석 보고서\n",
      "======================================================================\n",
      "# Iris 품종 분류 예측 성능 보고서\n",
      "\n",
      "## 1. 전체 예측 성능 요약\n",
      "\n",
      "이번 분석의 예측 데이터는 총 12회의 예측 수행을 기반으로 하고 있다. 평균 예측 신뢰도는 96.49%로 매우 높은 수준을 나타내고 있다. 이는 모델이 Iris 품종 분류에 대해 강력한 예측 성능을 가지고 있음을 시사한다. 예측 결과는 setosa, versicolor, virginica의 세 가지 품종으로 나뉘어 있다.\n",
      "\n",
      "## 2. 품종별 예측 패턴 분석\n",
      "\n",
      "- **Setosa**: 총 4회 예측되었으며 전체의 33.3%를 차지하고 있다. 이는 상대적으로 낮은 비율로, 모델이 다른 두 품종보다 setosa에 대해 덜 자주 예측하는 경향이 있음을 보인다.\n",
      "- **Versicolor**: 3회 예측으로 25.0%의 비율을 보인다. versicolor는 세 품종 중 예측 빈도가 가장 낮다.\n",
      "- **Virginica**: 가장 높은 5회의 예측 빈도로 41.7%를 차지하고 있다. 이는 모델이 virginica를 다른 품종보다 더 자주 예측함을 나타낸다.\n",
      "\n",
      "이러한 분포는 모델이 virginica에 대해 상대적으로 높은 인식 능력을 가지고 있음을 시사할 수 있다. 그러나 이를 통해 모델이 특정한 데이터셋에 편향되어 있을 가능성도 염두에 두어야 한다.\n",
      "\n",
      "## 3. 주요 특성별 경향성\n",
      "\n",
      "데이터에서 평균 특성값은 다음과 같다:\n",
      "- Sepal Length: 5.82 cm\n",
      "- Sepal Width: 3.12 cm\n",
      "- Petal Length: 3.99 cm\n",
      "- Petal Width: 1.39 cm\n",
      "\n",
      "이러한 평균치는 일반적인 Iris 데이터셋의 특성값과 유사하여 모델이 전체적으로 안정적인 특성 인식을 하고 있음을 보여준다. 각 특성의 평균값은 모델이 예측을 수행할 때 주요하게 고려하는 기준점이 될 수 있다.\n",
      "\n",
      "## 4. 인사이트 및 권장사항\n",
      "\n",
      "- **인사이트**: 현재 예측에서 virginica의 높은 예측 빈도는 데이터셋의 구성이나 모델의 가중치 설정에서 기인할 수 있다. 또한, 모든 품종에 대해 높은 신뢰도의 예측 결과가 관찰되고 있는 점은 고무적이다.\n",
      "- **권장사항**: 모델이 특정 품종에 대해 편향되지 않도록 다양한 데이터셋을 활용하여 학습할 필요가 있다. 특히 versicolor에 대한 예측 빈도가 낮기 때문에, 이 품종의 예측 정확도를 높이기 위한 추가 데이터 확보가 필요할 수 있다.\n",
      "\n",
      "## 5. 향후 개선 방향\n",
      "\n",
      "1. **데이터 다양성 강화**: 다양한 환경과 조건에서의 데이터를 추가하여 모델의 일반화 능력을 향상시킨다.\n",
      "2. **모델 재평가**: 모델의 하이퍼파라미터와 구조를 재검토하여 품종 간 예측의 균형을 맞춘다.\n",
      "3. **실시간 예측 피드백**: 실시간으로 예측 정확도를 피드백 받아 모델을 지속적으로 개선하는 시스템을 구축한다.\n",
      "4. **사용자 친화적 개선**: 비전문가도 쉽게 이해할 수 있도록 예측 결과에 대한 해설을 포함한 UI/UX 개선을 고려한다.\n",
      "\n",
      "이 보고서는 Iris 품종 분류 모델의 현재 성능과 향후 개선 방향에 대한 전략적인 통찰을 제공한다. 모델의 지속적인 성능 향상을 위해 제안된 개선 방향을 적극적으로 고려해야 한다.\n"
     ]
    }
   ],
   "source": [
    "print(\"분석 보고서 생성 중...\")\n",
    "report = chatbot.generate_report()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Iris 품종 분류 분석 보고서\")\n",
    "print(\"=\"*70)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보고서 저장 완료: context_store/analysis_report.md\n"
     ]
    }
   ],
   "source": [
    "report_path = 'context_store/analysis_report.md'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"보고서 저장 완료: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 시스템 현황 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Enable Agent 생태계 현황\n",
      "======================================================================\n",
      "\n",
      "[1] Enable Agent:\n",
      "   - Agent 이름: Iris Classification Agent\n",
      "   - 모델 타입: RandomForestClassifier\n",
      "   - 모델 정확도: 93.33%\n",
      "\n",
      "[2] 예측 통계:\n",
      "   - 총 예측 횟수: 12회\n",
      "   - 평균 신뢰도: 96.49%\n",
      "   - 품종별 분포:\n",
      "     * setosa: 4회 (33.3%)\n",
      "     * versicolor: 3회 (25.0%)\n",
      "     * virginica: 5회 (41.7%)\n",
      "\n",
      "[3] 챗봇 활동:\n",
      "   - 대화 수: 12개\n",
      "\n",
      "[4] 생성된 파일:\n",
      "   - 예측 로그: context_store/prediction_logs.json\n",
      "   - 통계 요약: context_store/prediction_summary.json\n",
      "   - 지식 베이스: context_store/knowledge_base.txt\n",
      "   - 분석 보고서: context_store/analysis_report.md\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "summary = context_builder.get_summary()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Enable Agent 생태계 현황\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"[1] Enable Agent:\")\n",
    "print(f\"   - Agent 이름: {agent.skill['agent_name']}\")\n",
    "print(f\"   - 모델 타입: {agent.metadata['model_type']}\")\n",
    "print(f\"   - 모델 정확도: {agent.metadata['accuracy']:.2%}\")\n",
    "print()\n",
    "\n",
    "if summary:\n",
    "    print(\"[2] 예측 통계:\")\n",
    "    print(f\"   - 총 예측 횟수: {summary['total_predictions']}회\")\n",
    "    print(f\"   - 평균 신뢰도: {summary['average_confidence']:.2%}\")\n",
    "    print(f\"   - 품종별 분포:\")\n",
    "    for species, count in summary['class_distribution'].items():\n",
    "        percentage = (count / summary['total_predictions']) * 100\n",
    "        print(f\"     * {species}: {count}회 ({percentage:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "print(\"[3] 챗봇 활동:\")\n",
    "print(f\"   - 대화 수: {len(chatbot.conversation_history)}개\")\n",
    "print()\n",
    "print(\"[4] 생성된 파일:\")\n",
    "print(f\"   - 예측 로그: {context_builder.log_file}\")\n",
    "print(f\"   - 통계 요약: {context_builder.summary_file}\")\n",
    "print(f\"   - 지식 베이스: {context_builder.knowledge_base_file}\")\n",
    "print(f\"   - 분석 보고서: context_store/analysis_report.md\")\n",
    "print()\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
