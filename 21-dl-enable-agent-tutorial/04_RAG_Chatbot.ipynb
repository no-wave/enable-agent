{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Agent Tutorial Part 4: RAG 챗봇 구현\n",
    "\n",
    "## 개요\n",
    "\n",
    "Part 3에서 구축한 지식 베이스를 활용하여 대화형 RAG 챗봇을 구현한다.\n",
    "\n",
    "## 학습 내용\n",
    "\n",
    "- RAG 챗봇 구현\n",
    "- 대화형 예측 인터페이스\n",
    "- 자동 분석 보고서 생성\n",
    "- 통합 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "print(\"라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 이전 Part에서 정의한 클래스 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceshipClassifier 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class SpaceshipClassifier(nn.Module):\n",
    "    \"\"\"Spaceship Titanic 이진 분류 신경망\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=10, hidden_dims=[64, 32, 16], dropout_rate=0.3):\n",
    "        super(SpaceshipClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if i < len(hidden_dims) - 1:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()\n",
    "\n",
    "print(\"SpaceshipClassifier 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceshipEnableAgent 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class SpaceshipEnableAgent:\n",
    "    \"\"\"Spaceship Titanic 예측 모델을 Enable Agent로 래핑한 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, skill_path: str):\n",
    "        with open(skill_path, 'r', encoding='utf-8') as f:\n",
    "            self.skill = yaml.safe_load(f)\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        model_path = self.skill['model_info']['model_path']\n",
    "        checkpoint = torch.load(model_path, map_location=self.device, weights_only=True)\n",
    "        \n",
    "        self.model = SpaceshipClassifier(\n",
    "            input_dim=checkpoint['input_dim'],\n",
    "            hidden_dims=checkpoint['hidden_dims'],\n",
    "            dropout_rate=checkpoint['dropout_rate']\n",
    "        ).to(self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        scaler_path = self.skill['model_info']['scaler_path']\n",
    "        self.scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        metadata_path = self.skill['model_info']['metadata_path']\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        self.encoding_maps = self.skill['encoding_maps']\n",
    "        self.client = OpenAI()\n",
    "        \n",
    "        print(f\"Enable Agent 초기화 완료: {self.skill['agent_name']}\")\n",
    "    \n",
    "    def get_capability_description(self) -> str:\n",
    "        return f\"\"\"\n",
    "Agent 이름: {self.skill['agent_name']}\n",
    "버전: {self.skill['version']}\n",
    "설명: {self.skill['description']}\n",
    "\n",
    "입력 파라미터:\n",
    "- HomePlanet: 출발 행성 (0: Earth, 1: Europa, 2: Mars, 3: Unknown)\n",
    "- CryoSleep: 냉동 수면 여부 (0: No, 1: Yes)\n",
    "- Destination: 목적지 (0: TRAPPIST-1e, 1: PSO J318.5-22, 2: 55 Cancri e)\n",
    "- Age: 나이\n",
    "- VIP: VIP 서비스 여부 (0: No, 1: Yes)\n",
    "- RoomService, FoodCourt, ShoppingMall, Spa, VRDeck: 각 서비스 지출액\n",
    "\n",
    "모델 정확도: {self.metadata['test_accuracy']:.4f}\n",
    "AUC-ROC: {self.metadata['test_auc_roc']:.4f}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    def _decode_categorical(self, input_data: Dict[str, Any]) -> Dict[str, str]:\n",
    "        decoded = {}\n",
    "        for field, value in input_data.items():\n",
    "            if field in self.encoding_maps:\n",
    "                decoded[field] = self.encoding_maps[field].get(value, str(value))\n",
    "            else:\n",
    "                decoded[field] = value\n",
    "        return decoded\n",
    "    \n",
    "    def predict(self, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        feature_names = self.metadata['feature_names']\n",
    "        input_array = np.array([[input_data[f] for f in feature_names]])\n",
    "        \n",
    "        input_scaled = self.scaler.transform(input_array)\n",
    "        input_tensor = torch.FloatTensor(input_scaled).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            probability = self.model(input_tensor).item()\n",
    "        \n",
    "        predicted_class = 'Transported' if probability > 0.5 else 'Not Transported'\n",
    "        confidence = probability if probability > 0.5 else (1 - probability)\n",
    "        \n",
    "        decoded_features = self._decode_categorical(input_data)\n",
    "        \n",
    "        return {\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"probability\": float(probability),\n",
    "            \"confidence\": float(confidence),\n",
    "            \"input_features\": input_data,\n",
    "            \"decoded_features\": decoded_features,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def generate_tool_definition(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"predict_spaceship_transport\",\n",
    "                \"description\": self.skill['description'],\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"HomePlanet\": {\"type\": \"integer\", \"description\": \"출발 행성 (0: Earth, 1: Europa, 2: Mars)\"},\n",
    "                        \"CryoSleep\": {\"type\": \"integer\", \"description\": \"냉동 수면 여부 (0: No, 1: Yes)\"},\n",
    "                        \"Destination\": {\"type\": \"integer\", \"description\": \"목적지 (0: TRAPPIST-1e, 1: PSO J318.5-22, 2: 55 Cancri e)\"},\n",
    "                        \"Age\": {\"type\": \"number\", \"description\": \"나이\"},\n",
    "                        \"VIP\": {\"type\": \"integer\", \"description\": \"VIP 여부 (0: No, 1: Yes)\"},\n",
    "                        \"RoomService\": {\"type\": \"number\", \"description\": \"룸서비스 지출액\"},\n",
    "                        \"FoodCourt\": {\"type\": \"number\", \"description\": \"푸드코트 지출액\"},\n",
    "                        \"ShoppingMall\": {\"type\": \"number\", \"description\": \"쇼핑몰 지출액\"},\n",
    "                        \"Spa\": {\"type\": \"number\", \"description\": \"스파 지출액\"},\n",
    "                        \"VRDeck\": {\"type\": \"number\", \"description\": \"VR 데크 지출액\"}\n",
    "                    },\n",
    "                    \"required\": [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\",\n",
    "                                 \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"SpaceshipEnableAgent 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionContextBuilder 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class PredictionContextBuilder:\n",
    "    \"\"\"예측 결과를 컨텍스트로 저장하고 관리하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, context_dir: str = 'context_store'):\n",
    "        self.context_dir = Path(context_dir)\n",
    "        self.context_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.log_file = self.context_dir / 'prediction_logs.json'\n",
    "        self.summary_file = self.context_dir / 'prediction_summary.json'\n",
    "        self.knowledge_base_file = self.context_dir / 'knowledge_base.txt'\n",
    "        \n",
    "        self.logs = self._load_logs()\n",
    "        \n",
    "        print(f\"Context Builder 초기화 완료\")\n",
    "        print(f\"저장된 예측 로그: {len(self.logs)}개\")\n",
    "    \n",
    "    def _load_logs(self) -> List[Dict[str, Any]]:\n",
    "        if self.log_file.exists():\n",
    "            with open(self.log_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return []\n",
    "    \n",
    "    def add_prediction(self, prediction_result: Dict[str, Any]):\n",
    "        self.logs.append(prediction_result)\n",
    "        \n",
    "        with open(self.log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.logs, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        self._update_summary()\n",
    "        self._update_knowledge_base()\n",
    "    \n",
    "    def _update_summary(self):\n",
    "        if not self.logs:\n",
    "            return\n",
    "        \n",
    "        total_predictions = len(self.logs)\n",
    "        class_counts = {'Transported': 0, 'Not Transported': 0}\n",
    "        probability_sum = 0\n",
    "        confidence_sum = 0\n",
    "        \n",
    "        for log in self.logs:\n",
    "            class_counts[log['predicted_class']] = class_counts.get(log['predicted_class'], 0) + 1\n",
    "            probability_sum += log['probability']\n",
    "            confidence_sum += log['confidence']\n",
    "        \n",
    "        summary = {\n",
    "            \"total_predictions\": total_predictions,\n",
    "            \"class_distribution\": class_counts,\n",
    "            \"average_probability\": probability_sum / total_predictions,\n",
    "            \"average_confidence\": confidence_sum / total_predictions,\n",
    "            \"last_updated\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(self.summary_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    def _update_knowledge_base(self):\n",
    "        if not self.logs:\n",
    "            return\n",
    "        \n",
    "        with open(self.summary_file, 'r', encoding='utf-8') as f:\n",
    "            summary = json.load(f)\n",
    "        \n",
    "        knowledge_text = f\"\"\"# Spaceship Titanic 예측 지식 베이스\n",
    "\n",
    "## 전체 통계\n",
    "- 총 예측 횟수: {summary['total_predictions']}회\n",
    "- 평균 이동 확률: {summary['average_probability']:.2%}\n",
    "- 평균 신뢰도: {summary['average_confidence']:.2%}\n",
    "\n",
    "## 예측 결과 분포\n",
    "\"\"\"\n",
    "        for cls, count in summary['class_distribution'].items():\n",
    "            pct = (count / summary['total_predictions']) * 100\n",
    "            knowledge_text += f\"- {cls}: {count}회 ({pct:.1f}%)\\n\"\n",
    "        \n",
    "        knowledge_text += \"\\n## 최근 예측 (최근 5개)\\n\\n\"\n",
    "        for i, log in enumerate(reversed(self.logs[-5:]), 1):\n",
    "            decoded = log.get('decoded_features', {})\n",
    "            knowledge_text += f\"\"\"### 예측 #{len(self.logs) - i + 1}\n",
    "- 결과: {log['predicted_class']} (확률: {log['probability']:.2%})\n",
    "- 출발: {decoded.get('HomePlanet', 'N/A')}, 냉동수면: {decoded.get('CryoSleep', 'N/A')}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        with open(self.knowledge_base_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(knowledge_text.strip())\n",
    "    \n",
    "    def get_knowledge_base_content(self) -> str:\n",
    "        if self.knowledge_base_file.exists():\n",
    "            with open(self.knowledge_base_file, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        return \"\"\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        if self.summary_file.exists():\n",
    "            with open(self.summary_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "\n",
    "print(\"PredictionContextBuilder 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. SpaceshipRAGChatbot 클래스 구현\n",
    "\n",
    "### 핵심 기능\n",
    "\n",
    "- **지식 베이스 통합**: 과거 예측 결과를 컨텍스트로 활용\n",
    "- **Function Calling**: 실시간 예측 수행\n",
    "- **자동 컨텍스트 업데이트**: 새로운 예측을 지식 베이스에 추가\n",
    "- **보고서 생성**: 전체 예측 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceshipRAGChatbot 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class SpaceshipRAGChatbot:\n",
    "    \"\"\"Spaceship Titanic 예측 지식을 활용하는 RAG 챗봇\"\"\"\n",
    "    \n",
    "    def __init__(self, agent: SpaceshipEnableAgent, context_builder: PredictionContextBuilder):\n",
    "        self.agent = agent\n",
    "        self.context_builder = context_builder\n",
    "        self.client = OpenAI()\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        print(\"RAG 챗봇 초기화 완료\")\n",
    "    \n",
    "    def _get_system_prompt(self) -> str:\n",
    "        knowledge_base = self.context_builder.get_knowledge_base_content()\n",
    "        agent_capability = self.agent.get_capability_description()\n",
    "        \n",
    "        return f\"\"\"\n",
    "당신은 Spaceship Titanic 승객의 다른 차원 이동 여부를 예측하는 AI 어시스턴트다.\n",
    "다음과 같은 역할을 수행한다:\n",
    "\n",
    "1. 사용자의 승객 정보를 받아 이동 여부를 예측한다\n",
    "2. 과거 예측 기록을 바탕으로 통계와 인사이트를 제공한다\n",
    "3. Spaceship Titanic의 배경과 특성에 대해 설명한다\n",
    "4. 예측 결과에 대한 상세한 분석과 해석을 제공한다\n",
    "\n",
    "## 사용 가능한 도구\n",
    "\n",
    "{agent_capability}\n",
    "\n",
    "## 과거 예측 지식 베이스\n",
    "\n",
    "{knowledge_base}\n",
    "\n",
    "## 응답 가이드라인\n",
    "\n",
    "- 친절하고 전문적인 톤을 유지한다\n",
    "- 기술 용어를 사용할 때는 쉬운 설명을 덧붙인다\n",
    "- 과거 예측 데이터를 활용하여 맥락있는 답변을 제공한다\n",
    "- 예측 요청 시 predict_spaceship_transport 함수를 호출한다\n",
    "- 문장의 끝은 ~다로 끝낸다\n",
    "\"\"\".strip()\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": self._get_system_prompt()}] + self.conversation_history\n",
    "        tools = [self.agent.generate_tool_definition()]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        response_message = response.choices[0].message\n",
    "        \n",
    "        if response_message.tool_calls:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if function_name == \"predict_spaceship_transport\":\n",
    "                    prediction_result = self.agent.predict(function_args)\n",
    "                    self.context_builder.add_prediction(prediction_result)\n",
    "                    \n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": None,\n",
    "                        \"tool_calls\": [tool_call]\n",
    "                    })\n",
    "                    \n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(prediction_result, ensure_ascii=False)\n",
    "                    })\n",
    "            \n",
    "            messages = [{\"role\": \"system\", \"content\": self._get_system_prompt()}] + self.conversation_history\n",
    "            \n",
    "            final_response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            assistant_message = final_response.choices[0].message.content\n",
    "        else:\n",
    "            assistant_message = response_message.content\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        summary = self.context_builder.get_summary()\n",
    "        knowledge_base = self.context_builder.get_knowledge_base_content()\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"당신은 데이터 분석 보고서를 작성하는 전문가다. 주어진 예측 데이터를 분석하여 경영진이 이해하기 쉬운 보고서를 작성한다. 문장의 끝은 ~다로 끝낸다.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "다음 Spaceship Titanic 예측 데이터를 바탕으로 상세한 분석 보고서를 작성해달라:\n",
    "\n",
    "## 요약 통계\n",
    "{json.dumps(summary, indent=2, ensure_ascii=False)}\n",
    "\n",
    "## 상세 예측 기록\n",
    "{knowledge_base}\n",
    "\n",
    "보고서에 다음 내용을 포함해달라:\n",
    "1. 전체 예측 성능 요약\n",
    "2. 이동/비이동 패턴 분석\n",
    "3. 주요 영향 요인 분석\n",
    "4. 인사이트 및 권장사항\n",
    "5. 향후 개선 방향\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        self.conversation_history = []\n",
    "        print(\"대화 히스토리 초기화 완료\")\n",
    "\n",
    "print(\"SpaceshipRAGChatbot 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. RAG 챗봇 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable Agent 초기화 완료: SpaceshipTransportPredictor\n",
      "Context Builder 초기화 완료\n",
      "저장된 예측 로그: 10개\n",
      "RAG 챗봇 초기화 완료\n",
      "\n",
      "모든 컴포넌트 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "agent = SpaceshipEnableAgent('skills/spaceship_agent_skill.yaml')\n",
    "context_builder = PredictionContextBuilder()\n",
    "chatbot = SpaceshipRAGChatbot(agent, context_builder)\n",
    "\n",
    "print(\"\\n모든 컴포넌트 초기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 대화형 데모\n",
    "\n",
    "RAG 챗봇과 대화하며 승객의 다른 차원 이동 여부를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_demo(user_input: str) -> str:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"사용자: {user_input}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    response = chatbot.chat(user_input)\n",
    "    \n",
    "    print(f\"챗봇: {response}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: 안녕하세요! Spaceship Titanic에 대해 알려주세요.\n",
      "----------------------------------------------------------------------\n",
      "챗봇: 안녕하세요! Spaceship Titanic은 미래의 우주 탐사에서 중요한 역할을 하는 거대한 우주선이다. 이 우주선은 다양한 출발 행성에서 온 승객들을 여러 목적지로 이동시키는 임무를 수행한다. 승객들은 다양한 이유로 여행을 떠나며, 이 중 일부는 다른 차원으로 이동할 수 있는 특별한 기회를 얻는다. \n",
      "\n",
      "Spaceship Titanic의 독특한 점은 차원 이동 기술을 사용하는 것이다. 승객들은 여행 중 냉동 수면(CryoSleep)을 선택할 수 있으며, 이 상태에서 차원 이동의 가능성이 높아진다. 또한, 우주선 내에서는 다양한 서비스가 제공되며, 승객들은 룸서비스, 푸드코트, 쇼핑몰, 스파, VR 데크 등에서 지출을 할 수 있다.\n",
      "\n",
      "Spaceship Titanic의 목적지는 대표적으로 TRAPPIST-1e, PSO J318.5-22, 55 Cancri e가 있으며, 각 목적지는 독특한 환경과 탐험 기회를 제공한다. 승객의 출발 행성과 목적지, 여행 중의 활동 등에 따라 차원 이동 여부가 결정된다.\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요! Spaceship Titanic은 미래의 우주 탐사에서 중요한 역할을 하는 거대한 우주선이다. 이 우주선은 다양한 출발 행성에서 온 승객들을 여러 목적지로 이동시키는 임무를 수행한다. 승객들은 다양한 이유로 여행을 떠나며, 이 중 일부는 다른 차원으로 이동할 수 있는 특별한 기회를 얻는다. \\n\\nSpaceship Titanic의 독특한 점은 차원 이동 기술을 사용하는 것이다. 승객들은 여행 중 냉동 수면(CryoSleep)을 선택할 수 있으며, 이 상태에서 차원 이동의 가능성이 높아진다. 또한, 우주선 내에서는 다양한 서비스가 제공되며, 승객들은 룸서비스, 푸드코트, 쇼핑몰, 스파, VR 데크 등에서 지출을 할 수 있다.\\n\\nSpaceship Titanic의 목적지는 대표적으로 TRAPPIST-1e, PSO J318.5-22, 55 Cancri e가 있으며, 각 목적지는 독특한 환경과 탐험 기회를 제공한다. 승객의 출발 행성과 목적지, 여행 중의 활동 등에 따라 차원 이동 여부가 결정된다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"안녕하세요! Spaceship Titanic에 대해 알려주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: \n",
      "지구에서 출발한 25세 승객이 있어요.\n",
      "냉동 수면 중이고, 목적지는 55 Cancri e입니다.\n",
      "VIP는 아니고, 모든 서비스 지출이 0이에요.\n",
      "이 승객이 다른 차원으로 이동될까요?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "챗봇: 지구에서 출발한 25세 승객은 냉동 수면 중이며, 목적지는 55 Cancri e이다. VIP 서비스는 이용하지 않았고, 모든 서비스 지출이 0이다. 이 승객은 다른 차원으로 이동될 확률이 약 66.66%로 예측되었다. 이는 과거 예측 기록에서 냉동 수면 상태인 승객들이 다른 차원으로 이동될 가능성이 높았던 패턴과 일치한다.\n",
      "\n",
      "이번 예측은 \"Transported\", 즉 다른 차원으로 이동될 것으로 예측되었으며, 확률이 66.66%로 비교적 높은 신뢰도를 보인다. 같은 조건에서 과거 예측에서도 냉동 수면 상태의 승객들이 이동될 가능성이 높았던 점을 고려하면, 이 승객도 다른 차원으로 이동될 가능성이 높다.\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'지구에서 출발한 25세 승객은 냉동 수면 중이며, 목적지는 55 Cancri e이다. VIP 서비스는 이용하지 않았고, 모든 서비스 지출이 0이다. 이 승객은 다른 차원으로 이동될 확률이 약 66.66%로 예측되었다. 이는 과거 예측 기록에서 냉동 수면 상태인 승객들이 다른 차원으로 이동될 가능성이 높았던 패턴과 일치한다.\\n\\n이번 예측은 \"Transported\", 즉 다른 차원으로 이동될 것으로 예측되었으며, 확률이 66.66%로 비교적 높은 신뢰도를 보인다. 같은 조건에서 과거 예측에서도 냉동 수면 상태의 승객들이 이동될 가능성이 높았던 점을 고려하면, 이 승객도 다른 차원으로 이동될 가능성이 높다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"\"\"\n",
    "지구에서 출발한 25세 승객이 있어요.\n",
    "냉동 수면 중이고, 목적지는 55 Cancri e입니다.\n",
    "VIP는 아니고, 모든 서비스 지출이 0이에요.\n",
    "이 승객이 다른 차원으로 이동될까요?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: \n",
      "이번에는 유로파에서 온 45세 VIP 승객이에요.\n",
      "냉동 수면은 하지 않고, TRAPPIST-1e로 가고 있어요.\n",
      "룸서비스 2000, 푸드코트 3000, 쇼핑몰 1000, 스파 5000, VR 데크 1500을 썼어요.\n",
      "예측해주세요.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "챗봇: 유로파에서 온 45세 VIP 승객은 냉동 수면을 하지 않고 TRAPPIST-1e로 가고 있다. 이 승객은 룸서비스, 푸드코트, 쇼핑몰, 스파, VR 데크에서 상당한 금액을 지출하였다. 이러한 조건에서 예측한 결과, 이 승객은 다른 차원으로 이동되지 않을 확률이 매우 높다. 정확히 말하면, 다른 차원으로 이동되지 않을 확률이 99.92%로 예측되었다.\n",
      "\n",
      "냉동 수면 상태가 아니고, VIP로서 많은 금액을 지출한 경우에도 다른 차원으로 이동될 확률이 낮음을 보여준다. 이와 같은 패턴은 과거 예측 기록에서도 자주 관찰되었으며, 냉동 수면을 하지 않는 승객들이 이동될 확률이 낮았다는 점과 일치한다.\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'유로파에서 온 45세 VIP 승객은 냉동 수면을 하지 않고 TRAPPIST-1e로 가고 있다. 이 승객은 룸서비스, 푸드코트, 쇼핑몰, 스파, VR 데크에서 상당한 금액을 지출하였다. 이러한 조건에서 예측한 결과, 이 승객은 다른 차원으로 이동되지 않을 확률이 매우 높다. 정확히 말하면, 다른 차원으로 이동되지 않을 확률이 99.92%로 예측되었다.\\n\\n냉동 수면 상태가 아니고, VIP로서 많은 금액을 지출한 경우에도 다른 차원으로 이동될 확률이 낮음을 보여준다. 이와 같은 패턴은 과거 예측 기록에서도 자주 관찰되었으며, 냉동 수면을 하지 않는 승객들이 이동될 확률이 낮았다는 점과 일치한다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_demo(\"\"\"\n",
    "이번에는 유로파에서 온 45세 VIP 승객이에요.\n",
    "냉동 수면은 하지 않고, TRAPPIST-1e로 가고 있어요.\n",
    "룸서비스 2000, 푸드코트 3000, 쇼핑몰 1000, 스파 5000, VR 데크 1500을 썼어요.\n",
    "예측해주세요.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "사용자: 지금까지의 예측 통계를 알려주세요.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_demo(\"지금까지의 예측 통계를 알려주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_demo(\"냉동 수면이 이동 확률에 어떤 영향을 미치나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 분석 보고서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"분석 보고서 생성 중...\")\n",
    "report = chatbot.generate_report()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Spaceship Titanic 예측 분석 보고서\")\n",
    "print(\"=\"*70)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = 'context_store/analysis_report.md'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"보고서 저장 완료: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 시스템 현황 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = context_builder.get_summary()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Enable Agent 생태계 현황\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"[1] Enable Agent:\")\n",
    "print(f\"   - Agent 이름: {agent.skill['agent_name']}\")\n",
    "print(f\"   - 모델 타입: {agent.metadata['model_type']}\")\n",
    "print(f\"   - 테스트 정확도: {agent.metadata['test_accuracy']:.2%}\")\n",
    "print(f\"   - AUC-ROC: {agent.metadata['test_auc_roc']:.2%}\")\n",
    "print()\n",
    "\n",
    "if summary:\n",
    "    print(\"[2] 예측 통계:\")\n",
    "    print(f\"   - 총 예측 횟수: {summary['total_predictions']}회\")\n",
    "    print(f\"   - 평균 신뢰도: {summary['average_confidence']:.2%}\")\n",
    "    print(f\"   - 결과별 분포:\")\n",
    "    for cls, count in summary['class_distribution'].items():\n",
    "        pct = (count / summary['total_predictions']) * 100\n",
    "        print(f\"     * {cls}: {count}회 ({pct:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "print(\"[3] 챗봇 활동:\")\n",
    "print(f\"   - 대화 수: {len(chatbot.conversation_history)}개\")\n",
    "print()\n",
    "print(\"[4] 생성된 파일:\")\n",
    "print(f\"   - 예측 로그: {context_builder.log_file}\")\n",
    "print(f\"   - 통계 요약: {context_builder.summary_file}\")\n",
    "print(f\"   - 지식 베이스: {context_builder.knowledge_base_file}\")\n",
    "print(f\"   - 분석 보고서: context_store/analysis_report.md\")\n",
    "print()\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
